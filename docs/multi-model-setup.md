# Trust CLI Multi-Model Setup Guide

## üéØ Overview

Trust CLI supports three different AI backends with intelligent fallback, giving you complete choice over your AI inference approach while maintaining privacy-first principles.

## üöÄ Quick Start Guide

### Option 1: Ollama (Recommended)

**Best for**: Fast setup, excellent performance, easy model management

```bash
# 1. Install Ollama
curl -fsSL https://ollama.ai/install.sh | sh

# 2. Start Ollama service
ollama serve

# 3. Pull a model
ollama pull qwen2.5:1.5b

# 4. Trust CLI automatically detects and uses Ollama
trust
```

### Option 2: HuggingFace Models

**Best for**: Complete offline operation, fine-grained control

```bash
# 1. Download models directly
trust model download qwen2.5-1.5b-instruct

# 2. Switch to downloaded model
trust model switch qwen2.5-1.5b-instruct

# 3. Trust CLI uses HuggingFace automatically
trust
```

### Option 3: Cloud Models (Fallback)

**Best for**: Maximum performance, latest capabilities

```bash
# 1. Enable cloud fallback
trust config set ai.cloud.enabled true

# 2. Configure authentication
trust auth login --provider google

# 3. Trust CLI uses cloud when local models unavailable
trust
```

## üîß Architecture Details

### Backend Selection Order

Trust CLI tries backends in this order:

1. **Ollama** (if running on localhost:11434)
2. **HuggingFace** (if GGUF models downloaded)
3. **Cloud** (if configured and enabled)

### Intelligent Fallback

- **Automatic Detection**: Trust CLI checks each backend's availability
- **Graceful Degradation**: Falls back to next available backend
- **User Control**: Can disable fallback or force specific backend

## ‚öôÔ∏è Configuration Management

### View Current Configuration

```bash
# Check current backend status
trust config show

# See which backend is active
trust status

# View AI configuration
trust config get ai
```

### Backend Preferences

```bash
# Set preferred backend
trust config set ai.preferredBackend ollama

# Change fallback order
trust config set ai.fallbackOrder "ollama,huggingface,cloud"

# Disable fallback (use only preferred backend)
trust config set ai.enableFallback false
```

### Ollama Configuration

```bash
# Set default model
trust config set ai.ollama.defaultModel qwen2.5:7b

# Adjust timeout for slower hardware
trust config set ai.ollama.timeout 180000  # 3 minutes

# Set custom Ollama URL
trust config set ai.ollama.baseUrl http://your-server:11434

# Set maximum tool calls
trust config set ai.ollama.maxToolCalls 5
```

### HuggingFace Configuration

```bash
# Enable/disable HuggingFace fallback
trust config set ai.huggingface.enabled true

# Enable GBNF grammar-based function calling
trust config set ai.huggingface.gbnfFunctions true
```

### Cloud Configuration

```bash
# Enable/disable cloud fallback
trust config set ai.cloud.enabled false

# Set cloud provider
trust config set ai.cloud.provider google  # or 'openai', 'anthropic'
```

## üìä Backend Comparison

| Feature              | Ollama    | HuggingFace | Cloud   |
| -------------------- | --------- | ----------- | ------- |
| **Setup**            | Simple    | Moderate    | Simple  |
| **Performance**      | Fast      | Medium      | Fastest |
| **Privacy**          | Private   | Private     | Shared  |
| **Offline**          | Yes       | Yes         | No      |
| **Model Selection**  | Extensive | Curated     | Latest  |
| **Tool Calling**     | Native    | GBNF        | Native  |
| **Resource Usage**   | Low       | Medium      | None    |
| **Model Management** | Built-in  | Manual      | None    |

## üéØ Recommended Setups

### Privacy-First Developer

```bash
# Complete local operation, no cloud fallback
trust config set ai.enableFallback false
trust config set ai.preferredBackend huggingface
trust config set ai.cloud.enabled false
trust model download phi-3.5-mini-instruct
```

### Performance-Optimized Developer

```bash
# Ollama primary, cloud fallback for heavy tasks
ollama pull qwen2.5:7b
trust config set ai.fallbackOrder "ollama,cloud,huggingface"
trust config set ai.cloud.enabled true
```

### Enterprise/Security Team

```bash
# Local-only deployment with security policies
trust config set ai.enableFallback false
trust config set ai.preferredBackend huggingface
trust config set ai.cloud.enabled false
trust config set ai.huggingface.gbnfFunctions true
```

### Hybrid Workflow Developer

```bash
# Ollama for general use, HuggingFace for sensitive work
ollama pull qwen2.5:7b
trust model download deepseek-r1-distill-7b
trust config set ai.fallbackOrder "ollama,huggingface,cloud"
```

## üîß Advanced Configuration

### Configuration File Location

All settings are stored in `~/.trustcli/config.json`:

```json
{
  "ai": {
    "preferredBackend": "ollama",
    "fallbackOrder": ["ollama", "huggingface", "cloud"],
    "enableFallback": true,
    "ollama": {
      "baseUrl": "http://localhost:11434",
      "defaultModel": "qwen2.5:1.5b",
      "timeout": 120000,
      "maxToolCalls": 3
    },
    "huggingface": {
      "enabled": true,
      "gbnfFunctions": true
    },
    "cloud": {
      "enabled": false,
      "provider": "google"
    }
  }
}
```

### Environment Variables

```bash
# Override backend selection
export TRUST_BACKEND=ollama

# Override Ollama model
export TRUST_OLLAMA_MODEL=qwen2.5:7b

# Override configuration directory
export TRUST_CONFIG_DIR=~/.custom-trust
```

## üõ†Ô∏è Troubleshooting

### Ollama Not Detected

```bash
# Check if Ollama is running
curl http://localhost:11434/api/tags

# Start Ollama service
ollama serve

# Check Ollama logs
journalctl -f -u ollama  # Linux systemd
```

### HuggingFace Models Not Loading

```bash
# Check downloaded models
trust model list

# Verify model integrity
trust model verify

# Download if missing
trust model download qwen2.5-1.5b-instruct
```

### Cloud Authentication Issues

```bash
# Check authentication status
trust auth status

# Re-authenticate
trust auth login --provider google

# Clear auth cache
trust auth logout
```

### Configuration Issues

```bash
# Reset to defaults
trust config reset

# Backup current config
cp ~/.trustcli/config.json ~/.trustcli/config.json.backup

# View current settings
trust config show
```

## üöÄ Performance Tips

### Ollama Optimization

```bash
# Use appropriate model size for your hardware
ollama pull qwen2.5:1.5b  # 2GB RAM
ollama pull qwen2.5:7b    # 8GB RAM
ollama pull llama3.1:8b   # 16GB RAM

# Increase timeout for slower hardware
trust config set ai.ollama.timeout 300000  # 5 minutes
```

### HuggingFace Local Optimization

```bash
# Enable GBNF for better function calling
trust config set ai.trustLocal.gbnfFunctions true

# Use appropriate quantization
trust model download phi-3.5-mini-instruct  # Q4_K_M (balanced)
```

### Memory Management

```bash
# Check system resources
trust perf status

# Get optimization suggestions
trust perf optimize

# Monitor during usage
trust perf watch
```

## üîí Security Considerations

### Local-Only Operation

```bash
# Disable all external connections
trust config set ai.cloud.enabled false
trust config set ai.fallbackOrder "ollama,huggingface"

# Verify no external calls
trust config show | grep -E "(cloud|external)"
```

### Model Verification

```bash
# Verify all models
trust model verify

# Check model integrity
trust model status

# Review model sources
trust model info qwen2.5-1.5b-instruct
```

### Privacy Audit

```bash
# Review current configuration
trust config show

# Check active backend
trust status

# Audit logs (if enabled)
trust logs show
```

## üìö Additional Resources

- [Trust CLI Vision Document](../TRUST_CLI_VISION.md)
- [Model Management Guide](../README.md#-model-management)
- [Performance Monitoring](../README.md#-performance-monitoring)
- [Privacy & Security](../README.md#-privacy--security-management)

---

**Document Version**: 1.0
**Last Updated**: January 2025
**Status**: Complete - reflects current implementation
